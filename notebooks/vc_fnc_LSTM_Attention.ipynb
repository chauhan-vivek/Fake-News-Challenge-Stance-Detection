{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM & Attention.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parth06/Fake-News-Challenge/blob/master/Neural%20Net/LSTM_%26_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyHz4P3kCoV",
        "colab_type": "code",
        "outputId": "c31be123-f8ab-4c65-c1a8-4c90810ac109",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!git clone https://github.com/parth06/Fake-News-Challenge.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Fake-News-Challenge' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnY7Um7MkFxY",
        "colab_type": "code",
        "outputId": "070c6f66-2288-4191-9ced-ccd02d824d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd Fake-News-Challenge/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Fake-News-Challenge\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM5zknkokpVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git submodule init\n",
        "!git submodule update"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "st1Y0_4OkxFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hey9M7eimA1_",
        "colab_type": "code",
        "outputId": "e3afc419-dd2d-4354-86d5-334daf019f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Y9DG_zyUlS",
        "colab_type": "code",
        "outputId": "a5fa24be-9562-4790-a1aa-4ba07c90e0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnyMTIv-UyWQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data/glove\n",
        "!mkdir data/glove_twitter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7rqXqTPL_Nj",
        "colab_type": "code",
        "outputId": "62d46ed0-e311-4334-9069-182053d8dd3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "!unzip glove.twitter.27B.zip -d data/glove_twitter/\n",
        "!unzip glove.6B.zip -d data/glove"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-07-26 12:06:55--  http://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.twitter.27B.zip [following]\n",
            "--2019-07-26 12:06:55--  https://nlp.stanford.edu/data/glove.twitter.27B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip [following]\n",
            "--2019-07-26 12:06:55--  http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1520408563 (1.4G) [application/zip]\n",
            "Saving to: ‘glove.twitter.27B.zip’\n",
            "\n",
            "glove.twitter.27B.z 100%[===================>]   1.42G  32.0MB/s    in 54s     \n",
            "\n",
            "2019-07-26 12:07:49 (26.9 MB/s) - ‘glove.twitter.27B.zip’ saved [1520408563/1520408563]\n",
            "\n",
            "--2019-07-26 12:07:50--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2019-07-26 12:07:50--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2019-07-26 12:07:50--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  31.0MB/s    in 25s     \n",
            "\n",
            "2019-07-26 12:08:16 (32.7 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.twitter.27B.zip\n",
            "  inflating: data/glove_twitter/glove.twitter.27B.25d.txt  \n",
            "  inflating: data/glove_twitter/glove.twitter.27B.50d.txt  \n",
            "  inflating: data/glove_twitter/glove.twitter.27B.100d.txt  \n",
            "  inflating: data/glove_twitter/glove.twitter.27B.200d.txt  \n",
            "Archive:  glove.6B.zip\n",
            "  inflating: data/glove/glove.6B.50d.txt  \n",
            "  inflating: data/glove/glove.6B.100d.txt  \n",
            "  inflating: data/glove/glove.6B.200d.txt  \n",
            "  inflating: data/glove/glove.6B.300d.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgqJr5uUVol8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm glove.twitter.27B.zip\n",
        "!rm glove.6B.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY9TfIgLruAi",
        "colab_type": "code",
        "outputId": "f86e2776-c771-4fbc-ef40-2858cdf97b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import csv\n",
        "import codecs\n",
        "import sys\n",
        "import pickle\n",
        "\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, LSTM, Embedding, Dropout, BatchNormalization, Activation, Bidirectional\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib as mpl\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import plot_model \n",
        "from IPython.display import Image\n",
        "import pydot\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "from string import punctuation\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "#from keras import initializations\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "tf_gpu_options = tf.GPUOptions(allow_growth = True) # per_process_gpu_memory_fraction=0.12,\n",
        "tf_session = tf.Session(config=tf.ConfigProto(gpu_options=tf_gpu_options))\n",
        "tf.keras.backend.set_session(tf_session)\n",
        "\n",
        "#biodirectional embedding\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Sgq7UByxO8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify the folder locations\n",
        "#W2V_DIR = './data/GoogleNews-vectors-negative300.bin' #\n",
        "GloVe_DIR = './data/glove_twitter/glove.twitter.27B.50d.txt'\n",
        "#the data directory\n",
        "DATA_DIR = './data/old'\n",
        "# These are some hyperparameters that can be tuned\n",
        "MAX_SENT_LEN = 300 #75(0.68), 150, 300 700(90% but too time comsuming)\n",
        "MAX_VOCAB_SIZE = 28000 #vocabulary\n",
        "LSTM_DIM = 50#len(embd[0])\n",
        "EMBEDDING_DIM = 50 #50 for GloVe 300 for w2v\n",
        "BATCH_SIZE = 128\n",
        "N_EPOCHS = 40 #40"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwClWBJCxaoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fix random seed for reproducibility\n",
        "seed = 1\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbNpmTk-xcu4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the text files of fnc data\n",
        "bodies = pd.read_csv(DATA_DIR + '/body_id.csv')\n",
        "    \n",
        "train_df = pd.read_csv(DATA_DIR + '/train.csv')\n",
        "\n",
        "validation_df = pd.read_csv(DATA_DIR + '/validation.csv')\n",
        "\n",
        "test_df = pd.read_csv(DATA_DIR + '/test.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl82l2uoN6Eh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df.replace('unrelated',1,True)\n",
        "train_df.replace('agree',2,True)\n",
        "train_df.replace('disagree',3,True)\n",
        "train_df.replace('discuss',4,True)\n",
        "\n",
        "validation_df.replace('unrelated',1,True)\n",
        "validation_df.replace('agree',2,True)\n",
        "validation_df.replace('disagree',3,True)\n",
        "validation_df.replace('discuss',4,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPmDqjM2CDQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unrelated:1 Related:0\n",
        "def f(row):\n",
        "    if row['Stance']==4:\n",
        "      return 1\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "train_df['Classify'] = train_df.apply(f, axis=1)\n",
        "validation_df['Classify'] = validation_df.apply(f, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5O2KhAAZtxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combine_df_train = train_df.join(bodies.set_index('Body ID'), on='Body ID')\n",
        "combine_df_validation = validation_df.join(bodies.set_index('Body ID'), on='Body ID')\n",
        "combine_df_test = test_df.join(bodies.set_index('Body ID'), on='Body ID')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zuJwLokZvUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pre-processing involves removal of puctuations and converting text to lower case\n",
        "word_seq_head_train = [text_to_word_sequence(head) for head in combine_df_train['Headline']]\n",
        "word_seq_bodies_train = [text_to_word_sequence(body) for body in combine_df_train['articleBody']]\n",
        "word_seq_head_validation = [text_to_word_sequence(head) for head in combine_df_validation['Headline']]\n",
        "word_seq_bodies_validation = [text_to_word_sequence(body) for body in combine_df_validation['articleBody']]\n",
        "word_seq_head_test = [text_to_word_sequence(head) for head in combine_df_test['Headline']]\n",
        "word_seq_bodies_test = [text_to_word_sequence(body) for body in combine_df_test['articleBody']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kirtV5WjZxEy",
        "colab_type": "code",
        "outputId": "861aa30e-7b4f-4be6-babb-d7bdcbc05ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('90th Percentile Sentence of headline:', np.percentile([len(seq) for seq in word_seq_head_train], 90))\n",
        "print('90th Percentile Sentence of body:', np.percentile([len(seq) for seq in word_seq_bodies_train], 50))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90th Percentile Sentence of headline: 16.0\n",
            "90th Percentile Sentence of body: 308.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCwL78HPZzcj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_seq = []\n",
        "for i in range(len(word_seq_head_train)):\n",
        "    word_seq.append(word_seq_head_train[i])\n",
        "for i in range(len(word_seq_bodies_train)):\n",
        "    word_seq.append(word_seq_bodies_train[i])\n",
        "\n",
        "# for i in range(len(word_seq_head_validation)):\n",
        "#     word_seq.append(word_seq_head_validation[i])\n",
        "# for i in range(len(word_seq_bodies_validation)):\n",
        "#     word_seq.append(word_seq_bodies_validation[i])\n",
        "    \n",
        "# for i in range(len(word_seq_head_test)):\n",
        "#     word_seq.append(word_seq_head_test[i])\n",
        "# for i in range(len(word_seq_bodies_test)):\n",
        "#     word_seq.append(word_seq_bodies_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAhTiqsbZ88A",
        "colab_type": "code",
        "outputId": "8d6fd10e-93c0-4407-a408-296007914759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "filter_list = '!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "MAX_VOCAB_SIZE = 5000\n",
        "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters=filter_list)\n",
        "tokenizer.fit_on_texts([seq for seq in word_seq])\n",
        "#because it only includes unique words(tokens)\n",
        "\n",
        "print(\"Number of words in vocabulary:\", len(tokenizer.word_index))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in vocabulary: 25128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAWEdWEpqN8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, EMBEDDING_DIM)) # +1 is because the matrix indices start with 0\n",
        "\n",
        "# for word, i in tokenizer.word_index.items(): # i=0 is the embedding for the zero padding\n",
        "#   try:\n",
        "#       embeddings_vector = embeddings[word]\n",
        "#   except KeyError:\n",
        "#       embeddings_vector = None\n",
        "#   if embeddings_vector is not None:\n",
        "#       embeddings_matrix[i] = embeddings_vector\n",
        "\n",
        "# del embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXtjcF6izK60",
        "colab_type": "code",
        "outputId": "0550f7b1-8bb2-4210-de21-215682cdb272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xtrain_headline = tokenizer.texts_to_matrix(word_seq_head_train, mode='freq')\n",
        "Xtrain_headline.shape\n",
        "\n",
        "Xtrain_body = tokenizer.texts_to_matrix(word_seq_bodies_train, mode='freq')\n",
        "Xtrain_body.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40350, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bugjyinQ0Wzx",
        "colab_type": "code",
        "outputId": "3ebb1390-9063-42f3-9726-6b9ac7b87ab0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xval_headline = tokenizer.texts_to_matrix(word_seq_head_validation, mode='freq')\n",
        "Xval_headline.shape\n",
        "\n",
        "Xval_body = tokenizer.texts_to_matrix(word_seq_bodies_validation, mode='freq')\n",
        "Xval_body.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9622, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnKnmCba5NEV",
        "colab_type": "code",
        "outputId": "c46ab249-0c8c-40b1-bab7-c35d8d925056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "Xtest_headline = tokenizer.texts_to_matrix(word_seq_head_test, mode='freq')\n",
        "Xtest_headline.shape\n",
        "\n",
        "Xtest_body = tokenizer.texts_to_matrix(word_seq_bodies_test, mode='freq')\n",
        "Xtest_body.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25413, 5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8C1rctJbzWps",
        "colab_type": "code",
        "outputId": "3170a59d-00c8-433a-999e-fb67e6966fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "model1_in = Input(shape=(5000,))\n",
        "model1_out = (model1_in)\n",
        "model1 = Model(model1_in, model1_out)\n",
        "\n",
        "model2_in = Input(shape=(5000,))\n",
        "model2_out = (model2_in)\n",
        "model2 = Model(model2_in, model2_out)\n",
        "\n",
        "\n",
        "concatenated = concatenate([model1_out, model2_out])\n",
        "layer_1 = Dense(600, activation='relu', name='layer_1') (concatenated)\n",
        "dropout_1 = Dropout(rate=0.5, name='dropout_1')(layer_1)\n",
        "layer_2 =Dense(600,  activation='relu', name='layer_2') (dropout_1)\n",
        "dropout_2 = Dropout(rate=0.5, name='dropout_2')(layer_2)\n",
        "layer_3 =Dense(600,  activation='relu', name='layer_3') (dropout_2)\n",
        "dropout_3 = Dropout(rate=0.5, name='dropout_3')(layer_3)\n",
        "out1 =  Dense(2, activation='softmax', name='output_layer1')(dropout_3)\n",
        "out2 = Dense(4, activation='softmax', name='output_layer2')(dropout_3)\n",
        "\n",
        "losses = {\n",
        "\t\"output_layer1\": \"categorical_crossentropy\",\n",
        "\t\"output_layer2\": \"categorical_crossentropy\",\n",
        "}\n",
        "lossWeights = {\"output_layer1\": 0.25, \"output_layer2\": 0.75}\n",
        "               \n",
        "merged_model = Model([model1_in, model2_in], [out1,out2])\n",
        "merged_model.compile(loss=losses, optimizer='adam', loss_weights=lossWeights,\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# checkpoint = ModelCheckpoint('weights.h5', monitor='val_acc',\n",
        "# save_best_only=True, verbose=2)\n",
        "# early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0726 12:00:36.275502 140477277935488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0726 12:00:36.278296 140477277935488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0726 12:00:36.296282 140477277935488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0726 12:00:36.319746 140477277935488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0726 12:00:36.334908 140477277935488 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0726 12:00:36.483913 140477277935488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0726 12:00:36.520627 140477277935488 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoSGChc11P5R",
        "colab_type": "code",
        "outputId": "a86f7c08-fe10-410a-a631-8e4258fe6e0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "merged_model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 5000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 5000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 10000)        0           input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_1 (Dense)                 (None, 600)          6000600     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 600)          0           layer_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_2 (Dense)                 (None, 600)          360600      dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 600)          0           layer_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_3 (Dense)                 (None, 600)          360600      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 600)          0           layer_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "output_layer1 (Dense)           (None, 2)            1202        dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "output_layer2 (Dense)           (None, 4)            2404        dropout_3[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 6,725,406\n",
            "Trainable params: 6,725,406\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRUMRgvY2lNA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(merged_model, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkJROoZd79SR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = combine_df_train['Stance']\n",
        "y_val = combine_df_validation['Stance']\n",
        "#Encode class values as integers\n",
        "encoder_train = LabelEncoder()\n",
        "encoder_train.fit(y_train)\n",
        "encoded_train = encoder_train.transform(y_train)\n",
        "encoded_val = encoder_train.transform(y_val)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y_train = np_utils.to_categorical(encoded_train)\n",
        "dummy_y_val = np_utils.to_categorical(encoded_val)\n",
        "\n",
        "y1_train = train_df['Classify']\n",
        "y1_val = validation_df['Classify']\n",
        "#Encode class values as integers\n",
        "encoder_train = LabelEncoder()\n",
        "encoder_train.fit(y1_train)\n",
        "encoded_train = encoder_train.transform(y1_train)\n",
        "encoded_val = encoder_train.transform(y1_val)\n",
        "# convert integers to dummy variables (i.e. one hot encoded)\n",
        "dummy_y1_train = np_utils.to_categorical(encoded_train)\n",
        "dummy_y1_val = np_utils.to_categorical(encoded_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX-A8m2l1Fzo",
        "colab_type": "code",
        "outputId": "7d7d5ae1-c6df-4cfb-c32f-27d8c60f9bb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        }
      },
      "source": [
        "merged_model.fit([Xtrain_headline, Xtrain_body], y=[dummy_y1_train,dummy_y_train], batch_size=128, epochs=20, \n",
        "                 validation_data=([Xval_headline,Xval_body],[dummy_y1_val,dummy_y_val]),verbose=1, shuffle=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 12:00:38.217474 140477277935488 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 40350 samples, validate on 9622 samples\n",
            "Epoch 1/20\n",
            "40350/40350 [==============================] - 12s 307us/step - loss: 0.5610 - output_layer1_loss: 0.3576 - output_layer2_loss: 0.6288 - output_layer1_acc: 0.8564 - output_layer2_acc: 0.7804 - val_loss: 0.4137 - val_output_layer1_loss: 0.2583 - val_output_layer2_loss: 0.4655 - val_output_layer1_acc: 0.8921 - val_output_layer2_acc: 0.8312\n",
            "Epoch 2/20\n",
            "40350/40350 [==============================] - 9s 230us/step - loss: 0.2169 - output_layer1_loss: 0.1343 - output_layer2_loss: 0.2444 - output_layer1_acc: 0.9467 - output_layer2_acc: 0.9139 - val_loss: 0.2977 - val_output_layer1_loss: 0.1792 - val_output_layer2_loss: 0.3372 - val_output_layer1_acc: 0.9226 - val_output_layer2_acc: 0.8716\n",
            "Epoch 3/20\n",
            "40350/40350 [==============================] - 9s 232us/step - loss: 0.1278 - output_layer1_loss: 0.0798 - output_layer2_loss: 0.1438 - output_layer1_acc: 0.9685 - output_layer2_acc: 0.9465 - val_loss: 0.2446 - val_output_layer1_loss: 0.1612 - val_output_layer2_loss: 0.2724 - val_output_layer1_acc: 0.9382 - val_output_layer2_acc: 0.9027\n",
            "Epoch 4/20\n",
            "40350/40350 [==============================] - 9s 225us/step - loss: 0.0916 - output_layer1_loss: 0.0549 - output_layer2_loss: 0.1039 - output_layer1_acc: 0.9799 - output_layer2_acc: 0.9609 - val_loss: 0.2502 - val_output_layer1_loss: 0.1762 - val_output_layer2_loss: 0.2749 - val_output_layer1_acc: 0.9296 - val_output_layer2_acc: 0.9063\n",
            "Epoch 5/20\n",
            "40350/40350 [==============================] - 9s 225us/step - loss: 0.0686 - output_layer1_loss: 0.0412 - output_layer2_loss: 0.0778 - output_layer1_acc: 0.9848 - output_layer2_acc: 0.9704 - val_loss: 0.2449 - val_output_layer1_loss: 0.1765 - val_output_layer2_loss: 0.2677 - val_output_layer1_acc: 0.9334 - val_output_layer2_acc: 0.9106\n",
            "Epoch 6/20\n",
            "40350/40350 [==============================] - 11s 281us/step - loss: 0.0579 - output_layer1_loss: 0.0332 - output_layer2_loss: 0.0661 - output_layer1_acc: 0.9880 - output_layer2_acc: 0.9756 - val_loss: 0.2706 - val_output_layer1_loss: 0.1728 - val_output_layer2_loss: 0.3032 - val_output_layer1_acc: 0.9408 - val_output_layer2_acc: 0.9086\n",
            "Epoch 7/20\n",
            "40350/40350 [==============================] - 12s 288us/step - loss: 0.0481 - output_layer1_loss: 0.0276 - output_layer2_loss: 0.0549 - output_layer1_acc: 0.9901 - output_layer2_acc: 0.9800 - val_loss: 0.2636 - val_output_layer1_loss: 0.1846 - val_output_layer2_loss: 0.2900 - val_output_layer1_acc: 0.9414 - val_output_layer2_acc: 0.9195\n",
            "Epoch 8/20\n",
            "40350/40350 [==============================] - 11s 273us/step - loss: 0.0420 - output_layer1_loss: 0.0229 - output_layer2_loss: 0.0484 - output_layer1_acc: 0.9920 - output_layer2_acc: 0.9821 - val_loss: 0.2603 - val_output_layer1_loss: 0.1813 - val_output_layer2_loss: 0.2867 - val_output_layer1_acc: 0.9436 - val_output_layer2_acc: 0.9211\n",
            "Epoch 9/20\n",
            "40350/40350 [==============================] - 12s 286us/step - loss: 0.0385 - output_layer1_loss: 0.0203 - output_layer2_loss: 0.0446 - output_layer1_acc: 0.9928 - output_layer2_acc: 0.9839 - val_loss: 0.3065 - val_output_layer1_loss: 0.2303 - val_output_layer2_loss: 0.3319 - val_output_layer1_acc: 0.9328 - val_output_layer2_acc: 0.9132\n",
            "Epoch 10/20\n",
            "40350/40350 [==============================] - 12s 289us/step - loss: 0.0347 - output_layer1_loss: 0.0193 - output_layer2_loss: 0.0399 - output_layer1_acc: 0.9932 - output_layer2_acc: 0.9857 - val_loss: 0.2737 - val_output_layer1_loss: 0.2065 - val_output_layer2_loss: 0.2961 - val_output_layer1_acc: 0.9425 - val_output_layer2_acc: 0.9238\n",
            "Epoch 11/20\n",
            "40350/40350 [==============================] - 11s 280us/step - loss: 0.0298 - output_layer1_loss: 0.0162 - output_layer2_loss: 0.0343 - output_layer1_acc: 0.9943 - output_layer2_acc: 0.9876 - val_loss: 0.2665 - val_output_layer1_loss: 0.1996 - val_output_layer2_loss: 0.2888 - val_output_layer1_acc: 0.9448 - val_output_layer2_acc: 0.9248\n",
            "Epoch 12/20\n",
            "40350/40350 [==============================] - 11s 284us/step - loss: 0.0275 - output_layer1_loss: 0.0150 - output_layer2_loss: 0.0317 - output_layer1_acc: 0.9947 - output_layer2_acc: 0.9881 - val_loss: 0.2718 - val_output_layer1_loss: 0.2042 - val_output_layer2_loss: 0.2943 - val_output_layer1_acc: 0.9443 - val_output_layer2_acc: 0.9251\n",
            "Epoch 13/20\n",
            "40350/40350 [==============================] - 12s 296us/step - loss: 0.0236 - output_layer1_loss: 0.0131 - output_layer2_loss: 0.0271 - output_layer1_acc: 0.9954 - output_layer2_acc: 0.9908 - val_loss: 0.3121 - val_output_layer1_loss: 0.2449 - val_output_layer2_loss: 0.3345 - val_output_layer1_acc: 0.9366 - val_output_layer2_acc: 0.9188\n",
            "Epoch 14/20\n",
            "40350/40350 [==============================] - 12s 292us/step - loss: 0.0218 - output_layer1_loss: 0.0118 - output_layer2_loss: 0.0251 - output_layer1_acc: 0.9962 - output_layer2_acc: 0.9909 - val_loss: 0.3213 - val_output_layer1_loss: 0.2537 - val_output_layer2_loss: 0.3439 - val_output_layer1_acc: 0.9407 - val_output_layer2_acc: 0.9258\n",
            "Epoch 15/20\n",
            "40350/40350 [==============================] - 12s 290us/step - loss: 0.0226 - output_layer1_loss: 0.0131 - output_layer2_loss: 0.0257 - output_layer1_acc: 0.9954 - output_layer2_acc: 0.9909 - val_loss: 0.2757 - val_output_layer1_loss: 0.2041 - val_output_layer2_loss: 0.2996 - val_output_layer1_acc: 0.9442 - val_output_layer2_acc: 0.9289\n",
            "Epoch 16/20\n",
            "40350/40350 [==============================] - 12s 290us/step - loss: 0.0211 - output_layer1_loss: 0.0127 - output_layer2_loss: 0.0240 - output_layer1_acc: 0.9961 - output_layer2_acc: 0.9924 - val_loss: 0.3030 - val_output_layer1_loss: 0.2273 - val_output_layer2_loss: 0.3282 - val_output_layer1_acc: 0.9408 - val_output_layer2_acc: 0.9238\n",
            "Epoch 17/20\n",
            "40350/40350 [==============================] - 12s 292us/step - loss: 0.0180 - output_layer1_loss: 0.0105 - output_layer2_loss: 0.0205 - output_layer1_acc: 0.9964 - output_layer2_acc: 0.9926 - val_loss: 0.3264 - val_output_layer1_loss: 0.2501 - val_output_layer2_loss: 0.3518 - val_output_layer1_acc: 0.9414 - val_output_layer2_acc: 0.9251\n",
            "Epoch 18/20\n",
            "40350/40350 [==============================] - 12s 286us/step - loss: 0.0180 - output_layer1_loss: 0.0107 - output_layer2_loss: 0.0205 - output_layer1_acc: 0.9964 - output_layer2_acc: 0.9930 - val_loss: 0.3271 - val_output_layer1_loss: 0.2477 - val_output_layer2_loss: 0.3536 - val_output_layer1_acc: 0.9443 - val_output_layer2_acc: 0.9261\n",
            "Epoch 19/20\n",
            "40350/40350 [==============================] - 12s 287us/step - loss: 0.0152 - output_layer1_loss: 0.0086 - output_layer2_loss: 0.0175 - output_layer1_acc: 0.9971 - output_layer2_acc: 0.9943 - val_loss: 0.3325 - val_output_layer1_loss: 0.2517 - val_output_layer2_loss: 0.3594 - val_output_layer1_acc: 0.9432 - val_output_layer2_acc: 0.9209\n",
            "Epoch 20/20\n",
            "40350/40350 [==============================] - 12s 290us/step - loss: 0.0162 - output_layer1_loss: 0.0096 - output_layer2_loss: 0.0185 - output_layer1_acc: 0.9969 - output_layer2_acc: 0.9938 - val_loss: 0.3182 - val_output_layer1_loss: 0.2456 - val_output_layer2_loss: 0.3424 - val_output_layer1_acc: 0.9402 - val_output_layer2_acc: 0.9239\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc25c037160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJTbwWQ85mCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y,y_test = merged_model.predict([Xtest_headline,Xtest_body])\n",
        "y_test = np.argmax(y_test,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DspNEESe5mPm",
        "colab_type": "code",
        "outputId": "97dde5cc-505d-4f87-eb8c-d332708ffbc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "ans = pd.DataFrame(y_test)\n",
        "ans.replace(0,'unrelated',True)\n",
        "ans.replace(1,'agree',True)\n",
        "ans.replace(2,'disagree',True)\n",
        "ans.replace(3,'discuss',True)\n",
        "ans.head()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>discuss</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>unrelated</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0\n",
              "0    discuss\n",
              "1  unrelated\n",
              "2  unrelated\n",
              "3  unrelated\n",
              "4  unrelated"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yM8GGJ60IaWC",
        "colab_type": "text"
      },
      "source": [
        "**Simple LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYjhXChuZ-mq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Combine headline and body together\n",
        "word_seq_train = [list(i) for i in word_seq_head_train]\n",
        "for i in range(len(word_seq_head_train)):\n",
        "    word_seq_train[i].extend(word_seq_bodies_train[i]) \n",
        "\n",
        "word_seq_validation = [list(i) for i in word_seq_head_validation]\n",
        "for i in range(len(word_seq_head_validation)):\n",
        "    word_seq_validation[i].extend(word_seq_bodies_validation[i]) \n",
        "    \n",
        "word_seq_test = [list(i) for i in word_seq_head_test]\n",
        "for i in range(len(word_seq_head_test)):\n",
        "    word_seq_test[i].extend(word_seq_bodies_test[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXS7DqixaBwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shorten the sentence to a fixed length\n",
        "# Convert the sequence of words to sequnce of indices\n",
        "X_train = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_train])\n",
        "X_train = pad_sequences(X_train, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_train = combine_df_train['Stance']\n",
        "\n",
        "X_val = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_validation])\n",
        "X_val = pad_sequences(X_val, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
        "y_val = combine_df_validation['Stance']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lejNymflaJ48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert the sequence of words to sequnce of indices\n",
        "X_test = tokenizer.texts_to_sequences([' '.join(seq[:MAX_SENT_LEN]) for seq in word_seq_test])\n",
        "X_test = pad_sequences(X_test, maxlen=MAX_SENT_LEN, padding='post', truncating='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16dMqPXBaQb1",
        "colab_type": "code",
        "outputId": "a6195757-ee72-49ba-8ec4-8e9304a3b5cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Load the word2vec embeddings \n",
        "#embeddings = gensim.models.KeyedVectors.load_word2vec_format(GloVe_DIR, binary=True)\n",
        "\n",
        "#GloVes Load\n",
        "glove_input_file = GloVe_DIR\n",
        "word2vec_output_file = 'glove.50d.txt.word2vec'\n",
        "glove2word2vec(glove_input_file, word2vec_output_file)\n",
        "embeddings = gensim.models.KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JY64ha71aT4h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an embedding matrix containing only the word's in our vocabulary\n",
        "# If the word does not have a pre-trained embedding, then randomly initialize the embedding\n",
        "embeddings_matrix = np.random.uniform(-0.05, 0.05, size=(len(tokenizer.word_index)+1, EMBEDDING_DIM)) # +1 is because the matrix indices start with 0\n",
        "for word, i in tokenizer.word_index.items(): # i=0 is the embedding for the zero padding\n",
        "    try:\n",
        "        embeddings_vector = embeddings[word]\n",
        "    except KeyError:\n",
        "        embeddings_vector = None\n",
        "        #none: if words in sentence don't have pre-trained corresponding embedding, then error occurs\n",
        "\n",
        "    if embeddings_vector is not None:\n",
        "        embeddings_matrix[i] = embeddings_vector\n",
        "        #if pre-trained word embedding exists，then let embeddings_matrix[i] is this embedding\n",
        "        #Wi:the ith row of embeddings_matrix\n",
        "        \n",
        "del embeddings\n",
        "#delete"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5fMvJdLam9n",
        "colab_type": "code",
        "outputId": "8491cba5-21ac-45de-f60e-8b78cdf94a35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Build a sequential model by stacking neural net units \n",
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(input_dim=len(tokenizer.word_index)+1,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable=False, name='word_embedding_layer', #False\n",
        "                          mask_zero=True))\n",
        "#mask_zero is to deal with padding problem\n",
        "#model.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='lstm_layer1'))) #bi(lstm)\n",
        "model_1.add(Bidirectional(LSTM(LSTM_DIM, return_sequences=False, name='Bidrectional_lstm_layer1')))\n",
        "# model_1.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.8\n",
        "# model_1.add(Dense(4, activation='softmax', name='output_layer'))\n",
        "model_1.add(Dropout(rate=0.8, name='dropout_1'))\n",
        "model_1.add(Activation(activation='relu', name='activation_1'))\n",
        "\n",
        "#model.add(Dense(8, name='dense_2'))\n",
        "# model.add(BatchNormalization(name='bn_2'))\n",
        "model_1.add(Dropout(rate=0.5, name='dropout_2'))\n",
        "model_1.add(Activation(activation='relu', name='activation_2'))\n",
        "\n",
        "model_1.add(Dense(4, activation='softmax', name='output_layer'))\n",
        "model_1.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0726 12:13:03.954757 140477277935488 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_embedding_layer (Embedd (None, None, 50)          1256450   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 100)               40400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 4)                 404       \n",
            "=================================================================\n",
            "Total params: 1,297,254\n",
            "Trainable params: 40,804\n",
            "Non-trainable params: 1,256,450\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWMIwZBjapAQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_model(model_1, to_file='bidirectional_model.png', show_layer_names=True, show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyVmSCtya0bM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir result\n",
        "!mkdir result/lstm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzY6QVkKasJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath=\"./result/lstmBidirectional_lstm_150token_lr0.001_trainable_{epoch:02d}_{val_acc:.4f}.h5\"\n",
        "checkpoint = callbacks.ModelCheckpoint(filepath, \n",
        "                                       monitor='val_acc', \n",
        "                                       verbose=0, \n",
        "                                       save_best_only=True)\n",
        "es = callbacks.EarlyStopping(monitor='val_acc', mode='max',patience=2)\n",
        "callbacks_list1 = [checkpoint,es]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "una1mY9VbB63",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#before trainning model, we need to compile it\n",
        "#use adam optimizer\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_qII2sWbETK",
        "colab_type": "code",
        "outputId": "d7329f7b-7e30-4aa9-da5f-59080e4a37b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "history_3 = model_1.fit(X_train, dummy_y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=N_EPOCHS,\n",
        "          validation_data=(X_val, dummy_y_val),callbacks = callbacks_list1)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40350 samples, validate on 9622 samples\n",
            "Epoch 1/40\n",
            "40350/40350 [==============================] - 514s 13ms/step - loss: 0.9125 - acc: 0.7185 - val_loss: 0.8129 - val_acc: 0.7169\n",
            "Epoch 2/40\n",
            "40350/40350 [==============================] - 521s 13ms/step - loss: 0.8337 - acc: 0.7349 - val_loss: 0.7815 - val_acc: 0.7169\n",
            "Epoch 3/40\n",
            "40350/40350 [==============================] - 519s 13ms/step - loss: 0.7898 - acc: 0.7354 - val_loss: 0.7605 - val_acc: 0.7169\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITfSu67mbGMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model_1.predict_classes(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm-7j3QrUTkF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans = pd.DataFrame(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhPqI30XVKYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx5s36XPVN6D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans.replace(0,'unrelated',True)\n",
        "ans.replace(1,'agree',True)\n",
        "ans.replace(2,'disagree',True)\n",
        "ans.replace(3,'discuss',True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-tKKhYPWXI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAKxFFPzWZBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ans.to_csv(\"stance.csv\",header=False,index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w68Py1_WdlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCwx8yaweeOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history_3.history['acc'])\n",
        "plt.plot(history_3.history['val_acc'])\n",
        "plt.title('model accuracy(Truncation: 150 Epoch: 10)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtM9v6foi08n",
        "colab_type": "code",
        "outputId": "51fa078f-523b-4c4e-caa9-0ccf1cdd7ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from feature_engineering import refuting_features, polarity_features, hand_features, gen_or_load_feats\n",
        "from feature_engineering import word_overlap_features\n",
        "from utils.dataset import DataSet\n",
        "from utils.generate_test_splits import kfold_split, get_stances_for_folds\n",
        "from utils.score import report_score, LABELS, score_submission\n",
        "\n",
        "from utils.system import parse_params, check_version\n",
        "def generate_features(stances,dataset,name):\n",
        "    h, b, y = [],[],[]\n",
        "\n",
        "    for stance in stances:\n",
        "        y.append(LABELS.index(stance['Stance']))\n",
        "        h.append(stance['Headline'])\n",
        "        b.append(dataset.articles[stance['Body ID']])\n",
        "\n",
        "    return y\n",
        "  \n",
        "\n",
        "competition_dataset = DataSet(\"competition_test\")\n",
        "y_competition = generate_features(competition_dataset.stances, competition_dataset, \"competition\")\n",
        "\n",
        "Xs = dict()\n",
        "ys = dict()\n",
        "\n",
        "# Load/Precompute all features now\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading dataset\n",
            "Total stances: 25413\n",
            "Total bodies: 904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GkPcXf2eewZ",
        "colab_type": "code",
        "outputId": "abcc7125-ce2a-47b9-9bd4-3e3c2cb327a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Run on competition dataset\n",
        "actual = [LABELS[int(a)] for a in y_competition]\n",
        "\n",
        "print(\"Scores on the test set\")\n",
        "report_score(actual,ans[0])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scores on the test set\n",
            "-------------------------------------------------------------\n",
            "|           |   agree   | disagree  |  discuss  | unrelated |\n",
            "-------------------------------------------------------------\n",
            "|   agree   |    395    |    173    |    612    |    723    |\n",
            "-------------------------------------------------------------\n",
            "| disagree  |    125    |    60     |    223    |    289    |\n",
            "-------------------------------------------------------------\n",
            "|  discuss  |    216    |    209    |   2582    |   1457    |\n",
            "-------------------------------------------------------------\n",
            "| unrelated |    685    |    810    |   3560    |   13294   |\n",
            "-------------------------------------------------------------\n",
            "Score: 6750.0 out of 11651.25\t(57.93369810106212%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "57.93369810106212"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72SBo9fQkGjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZihcbYqgZt6M",
        "colab_type": "code",
        "outputId": "3502faa5-f5b3-495a-9e47-0bf23ca2bfb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Embedding(input_dim=len(tokenizer.word_index)+1, input_length = MAX_SENT_LEN,\n",
        "                          output_dim=EMBEDDING_DIM,\n",
        "                          weights = [embeddings_matrix], trainable= False, name='word_embedding_layer', \n",
        "                          mask_zero=True)) # trainable=True results in overfitting\n",
        "\n",
        "model_2.add(LSTM(LSTM_DIM, return_sequences=True, name='lstm_layer')) # Can try Bidirectional-LSTM\n",
        "model_2.add(Dropout(rate=0.8, name='dropout_1')) # Can try varying dropout rates, in paper suggest 0.2\n",
        "model_2.add(Activation(activation='relu', name='activation_1'))\n",
        "#output (batch_size, timesteps, input_dim)\n",
        "model_2.add(Attention(step_dim=300))\n",
        "model_2.add(Dense(4, activation='softmax', name='output_layer'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0715 18:41:18.151100 140300798273408 nn_ops.py:4224] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wY8zzykYZws5",
        "colab_type": "code",
        "outputId": "229ca6f4-2b26-4b2c-ad79-ccdb8dc18639",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "model_2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "word_embedding_layer (Embedd (None, 300, 50)           1393700   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 300, 100)          60400     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 300, 100)          0         \n",
            "_________________________________________________________________\n",
            "attention_2 (Attention)      (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 4)                 404       \n",
            "=================================================================\n",
            "Total params: 1,454,904\n",
            "Trainable params: 61,204\n",
            "Non-trainable params: 1,393,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLsfvYZafdxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optimizers.Adam(lr=0.001) # Try a different learning rate\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLBNPFcJiBCr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = callbacks.EarlyStopping(monitor='val_acc', mode='max',patience=3)\n",
        "callbacks_list2 = [es]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdBuiEfCiE8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history2 = model_2.fit(X_train, dummy_y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=1,\n",
        "          validation_data=(X_val, dummy_y_val),\n",
        "          callbacks = callbacks_list2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DZjx9bxiZS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history2.history['acc'])\n",
        "plt.plot(history2.history['val_acc'])\n",
        "plt.title('model accuracy(Truncation: 150 Epoch: 10)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC5jSwayilhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model_2.predict_classes(X_test)\n",
        "ans = pd.DataFrame(y)\n",
        "ans.head()\n",
        "\n",
        "ans.replace(1,'unrelated',True)\n",
        "ans.replace(2,'agree',True)\n",
        "ans.replace(3,'disagree',True)\n",
        "ans.replace(4,'discuss',True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn6p1NTJiHhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Scores on the test set\")\n",
        "report_score(actual,ans[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMudEuVci4qP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://www.kaggle.com/takuok/bidirectional-lstm-and-attention-lb-0-043"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}